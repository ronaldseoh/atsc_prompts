{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf9e3977",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [15]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f60812",
   "metadata": {
    "id": "xf3lVTZYhbzA",
    "papermill": {
     "duration": 0.104488,
     "end_time": "2021-05-14T20:23:00.607719",
     "exception": false,
     "start_time": "2021-05-14T20:23:00.503231",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Initial Setups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a24fb74",
   "metadata": {
    "id": "2ORFXeezn5Og",
    "papermill": {
     "duration": 0.065754,
     "end_time": "2021-05-14T20:23:00.779095",
     "exception": false,
     "start_time": "2021-05-14T20:23:00.713341",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## (Google Colab use only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f0519bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-14T20:23:00.929446Z",
     "iopub.status.busy": "2021-05-14T20:23:00.928767Z",
     "iopub.status.idle": "2021-05-14T20:23:00.932706Z",
     "shell.execute_reply": "2021-05-14T20:23:00.933213Z"
    },
    "executionInfo": {
     "elapsed": 53586,
     "status": "ok",
     "timestamp": 1615649208546,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "YFAQ6IgXn8FK",
    "outputId": "3db39796-e928-4077-f2ea-1609876a1536",
    "papermill": {
     "duration": 0.088448,
     "end_time": "2021-05-14T20:23:00.933394",
     "exception": false,
     "start_time": "2021-05-14T20:23:00.844946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use Google Colab\n",
    "use_colab = False\n",
    "\n",
    "# Is this notebook running on Colab?\n",
    "# If so, then google.colab package (github.com/googlecolab/colabtools)\n",
    "# should be available in this environment\n",
    "\n",
    "# Previous version used importlib, but we could do the same thing with\n",
    "# just attempting to import google.colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    colab_available = True\n",
    "except:\n",
    "    colab_available = False\n",
    "\n",
    "if use_colab and colab_available:\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # cd to the appropriate working directory under my Google Drive\n",
    "    %cd '/content/drive/My Drive/cs696ds_lexalytics/Prompting Experiments'\n",
    "    \n",
    "    # Install packages specified in requirements\n",
    "    !pip install -r requirements.txt\n",
    "    \n",
    "    # List the directory contents\n",
    "    !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44ec420",
   "metadata": {
    "id": "tgzsHF7Zhbzo",
    "papermill": {
     "duration": 0.065069,
     "end_time": "2021-05-14T20:23:01.064421",
     "exception": false,
     "start_time": "2021-05-14T20:23:00.999352",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59a49dc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-14T20:23:01.203577Z",
     "iopub.status.busy": "2021-05-14T20:23:01.202911Z",
     "iopub.status.idle": "2021-05-14T20:23:01.206367Z",
     "shell.execute_reply": "2021-05-14T20:23:01.205776Z"
    },
    "executionInfo": {
     "elapsed": 53578,
     "status": "ok",
     "timestamp": 1615649208548,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "DUpGBmOJhbzs",
    "papermill": {
     "duration": 0.07626,
     "end_time": "2021-05-14T20:23:01.206494",
     "exception": false,
     "start_time": "2021-05-14T20:23:01.130234",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# We will use the following string ID to identify this particular (training) experiments\n",
    "# in directory paths and other settings\n",
    "experiment_id = 'supervised_nli_single_prompt_1_in_domain_restaurant_MNLI_base_seed_696'\n",
    "\n",
    "# Random seed\n",
    "random_seed = 696\n",
    "\n",
    "# path to pretrained nli model folder or the string \"textattack/bert-base-uncased-MNLI\"\n",
    "nli_model_path = \"textattack/bert-base-uncased-MNLI\"\n",
    "\n",
    "# Prompts to be added to the end of each review text\n",
    "sentiment_prompts = [\n",
    "    \"The {aspect} is good.\",\n",
    "    \"The {aspect} is bad.\"]\n",
    "\n",
    "#index of the prompts in the sentiment_prompts by polarity for later grouping\n",
    "pos_prompt_indexes = [0]\n",
    "neg_prompt_indexes = [1]\n",
    "\n",
    "testing_batch_size = 32\n",
    "testing_domain = 'restaurants' # 'laptops', 'restaurants', 'joint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb0d2962",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-14T20:23:01.345093Z",
     "iopub.status.busy": "2021-05-14T20:23:01.344447Z",
     "iopub.status.idle": "2021-05-14T20:23:01.347828Z",
     "shell.execute_reply": "2021-05-14T20:23:01.347204Z"
    },
    "papermill": {
     "duration": 0.075891,
     "end_time": "2021-05-14T20:23:01.347955",
     "exception": false,
     "start_time": "2021-05-14T20:23:01.272064",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "experiment_id = \"nli_few_shot_in_domain_laptops_16_MNLI-base_the_aspect_is_696\"\n",
    "random_seed = 696\n",
    "nli_model_path = \"textattack/bert-base-uncased-MNLI\"\n",
    "sentiment_prompts = [\"The {aspect} is good.\", \"The {aspect} is bad.\"]\n",
    "pos_prompt_indexes = [0]\n",
    "neg_prompt_indexes = [1]\n",
    "testing_batch_size = 8\n",
    "testing_domain = \"laptops\"\n",
    "sample_size = 16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafcb9a7",
   "metadata": {
    "id": "GYZesqTioMvF",
    "papermill": {
     "duration": 0.054794,
     "end_time": "2021-05-14T20:23:01.462488",
     "exception": false,
     "start_time": "2021-05-14T20:23:01.407694",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63b57ecb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-14T20:23:01.587716Z",
     "iopub.status.busy": "2021-05-14T20:23:01.587148Z",
     "iopub.status.idle": "2021-05-14T20:23:13.918827Z",
     "shell.execute_reply": "2021-05-14T20:23:13.919878Z"
    },
    "executionInfo": {
     "elapsed": 62491,
     "status": "ok",
     "timestamp": 1615649217470,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "MlK_-DrWhbzb",
    "outputId": "d7240323-9fb8-4b39-a919-61889e14a4a1",
    "papermill": {
     "duration": 12.400242,
     "end_time": "2021-05-14T20:23:13.920209",
     "exception": false,
     "start_time": "2021-05-14T20:23:01.519967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.6.13 |Anaconda, Inc.| (default, Feb 23 2021, 21:15:04) \n",
      "[GCC 7.3.0]\n",
      "NumPy version: 1.19.5\n",
      "PyTorch version: 1.7.1\n",
      "Transformers version: 4.3.3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import copy\n",
    "import inspect\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "import datasets\n",
    "import sklearn.metrics\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import tqdm\n",
    "\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "import utils\n",
    "\n",
    "# Random seed settings\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "# cuBLAS reproducibility\n",
    "# https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"\n",
    "torch.set_deterministic(True)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "# Print version information\n",
    "print(\"Python version: \" + sys.version)\n",
    "print(\"NumPy version: \" + np.__version__)\n",
    "print(\"PyTorch version: \" + torch.__version__)\n",
    "print(\"Transformers version: \" + transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2227bf",
   "metadata": {
    "id": "UWuR30eUoTWP",
    "papermill": {
     "duration": 0.068773,
     "end_time": "2021-05-14T20:23:14.083389",
     "exception": false,
     "start_time": "2021-05-14T20:23:14.014616",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## PyTorch GPU settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42daf6e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-14T20:23:14.873463Z",
     "iopub.status.busy": "2021-05-14T20:23:14.872088Z",
     "iopub.status.idle": "2021-05-14T20:23:14.876538Z",
     "shell.execute_reply": "2021-05-14T20:23:14.877584Z"
    },
    "executionInfo": {
     "elapsed": 62482,
     "status": "ok",
     "timestamp": 1615649217472,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "PfNlm-ykoSlM",
    "outputId": "cd87501f-5f8a-4a4f-ac74-b792c35183d0",
    "papermill": {
     "duration": 0.727869,
     "end_time": "2021-05-14T20:23:14.877886",
     "exception": false,
     "start_time": "2021-05-14T20:23:14.150017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Version: 10.2\n",
      "cuDNN Version: 7605\n",
      "CUDA Device Name: GeForce GTX TITAN X\n",
      "CUDA Capabilities: (5, 2)\n",
      "Number of CUDA devices: 1\n",
      "\n",
      "PyTorch device selected: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if torch.cuda.is_available():    \n",
    "    torch_device = torch.device('cuda')\n",
    "\n",
    "    # Set this to True to make your output immediately reproducible\n",
    "    # Note: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    # Disable 'benchmark' mode: Set this False if you want to measure running times more fairly\n",
    "    # Note: https://discuss.pytorch.org/t/what-does-torch-backends-cudnn-benchmark-do/5936\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    # Faster Host to GPU copies with page-locked memory\n",
    "    use_pin_memory = True\n",
    "    \n",
    "    # Number of compute devices to be used for training\n",
    "    training_device_count = torch.cuda.device_count()\n",
    "\n",
    "    # CUDA libraries version information\n",
    "    print(\"CUDA Version: \" + str(torch.version.cuda))\n",
    "    print(\"cuDNN Version: \" + str(torch.backends.cudnn.version()))\n",
    "    print(\"CUDA Device Name: \" + str(torch.cuda.get_device_name()))\n",
    "    print(\"CUDA Capabilities: \"+ str(torch.cuda.get_device_capability()))\n",
    "    print(\"Number of CUDA devices: \"+ str(training_device_count))\n",
    "    \n",
    "else:\n",
    "    torch_device = torch.device('cpu')\n",
    "    use_pin_memory = False\n",
    "    \n",
    "    # Number of compute devices to be used for training\n",
    "    training_device_count = 1\n",
    "\n",
    "print()\n",
    "print(\"PyTorch device selected:\", torch_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb38514",
   "metadata": {
    "id": "ayX5VRLfocFk",
    "papermill": {
     "duration": 0.068592,
     "end_time": "2021-05-14T20:23:15.045121",
     "exception": false,
     "start_time": "2021-05-14T20:23:14.976529",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare Datasets for Prompt-based Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a80c167",
   "metadata": {
    "id": "U9LAAJP-hbz7",
    "papermill": {
     "duration": 0.067176,
     "end_time": "2021-05-14T20:23:15.179281",
     "exception": false,
     "start_time": "2021-05-14T20:23:15.112105",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load the SemEval dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91049758",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124,
     "referenced_widgets": [
      "f918ef555397425e82189c25be52b864",
      "fe29b874150c49d394b67b8e112fa837",
      "47fa4d3ca48945798c59a4b95fb5ef4b",
      "e8fbb242c47c478ba21d5b2686a0b37c",
      "b35ab0c6049046f1a10838a1a4fdb19d",
      "ab847001167a415a8be9f2b7172f500b",
      "030c838b7a16478d8719b2de55aa94ba",
      "d82e377d2ec74ed6ad6c1ed2b421f82b",
      "74723ce0259440c89d881c7ad0be4204",
      "6aad513853944ee092dad62fe6a8dfeb",
      "c1d1afc7ef3b45d4860bcba6fe90763f",
      "a4eeffe099cf46e7aab9e096f5ba93af",
      "7d7d459f08f74b3db47ae51c0c1a7771",
      "8b1e70e3d7244398859ae6abaf945dfe",
      "bd56dc0d05434043bc19fafa63d59a1d",
      "1c5abc026f1e4c58acaa4b82b62c47e9"
     ]
    },
    "execution": {
     "iopub.execute_input": "2021-05-14T20:23:15.321856Z",
     "iopub.status.busy": "2021-05-14T20:23:15.321155Z",
     "iopub.status.idle": "2021-05-14T20:23:15.594349Z",
     "shell.execute_reply": "2021-05-14T20:23:15.593321Z"
    },
    "executionInfo": {
     "elapsed": 69406,
     "status": "ok",
     "timestamp": 1615649224407,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "gpL2uHPUhbz9",
    "outputId": "174ce16a-e9a2-4f7e-d9ae-441fecdfdddf",
    "papermill": {
     "duration": 0.348187,
     "end_time": "2021-05-14T20:23:15.594580",
     "exception": false,
     "start_time": "2021-05-14T20:23:15.246393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset sem_eval2014_task4_dataset (../dataset_cache/sem_eval2014_task4_dataset/SemEval2014Task4Dataset - Subtask 4/0.0.1/537edd3b5fdbdb1f3190419cf0a53a4fab3537bc666f17c8c75fa8d0b554e529)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset sem_eval2014_task4_dataset (../dataset_cache/sem_eval2014_task4_dataset/SemEval2014Task4Dataset - Subtask 4/0.0.1/537edd3b5fdbdb1f3190419cf0a53a4fab3537bc666f17c8c75fa8d0b554e529)\n"
     ]
    }
   ],
   "source": [
    "# Load semeval for both domains\n",
    "laptop_semeval_dataset = datasets.load_dataset(\n",
    "    os.path.abspath('../dataset_scripts/semeval2014_task4/semeval2014_task4.py'),\n",
    "    name=\"SemEval2014Task4Dataset - Subtask 4\",\n",
    "    data_files={\n",
    "        'test': '../dataset_files/semeval_2014/Laptops_Test_Gold.xml',\n",
    "        'train': '../dataset_files/semeval_2014/Laptop_Train_v2.xml',\n",
    "    },\n",
    "    cache_dir='../dataset_cache')\n",
    "\n",
    "restaurant_semeval_dataset = datasets.load_dataset(\n",
    "    os.path.abspath('../dataset_scripts/semeval2014_task4/semeval2014_task4.py'),\n",
    "    name=\"SemEval2014Task4Dataset - Subtask 4\",\n",
    "    data_files={\n",
    "        'test': '../dataset_files/semeval_2014/Restaurants_Test_Gold.xml',\n",
    "        'train': '../dataset_files/semeval_2014/Restaurants_Train_v2.xml',\n",
    "    },\n",
    "    cache_dir='../dataset_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2c4435f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-14T20:23:15.766211Z",
     "iopub.status.busy": "2021-05-14T20:23:15.765577Z",
     "iopub.status.idle": "2021-05-14T20:23:15.768938Z",
     "shell.execute_reply": "2021-05-14T20:23:15.768311Z"
    },
    "executionInfo": {
     "elapsed": 69403,
     "status": "ok",
     "timestamp": 1615649224415,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "Gi5m8AbPj1iJ",
    "papermill": {
     "duration": 0.078062,
     "end_time": "2021-05-14T20:23:15.769065",
     "exception": false,
     "start_time": "2021-05-14T20:23:15.691003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_dic_test = {\n",
    "    \"laptops\": laptop_semeval_dataset['test'],\n",
    "    \"restaurants\": restaurant_semeval_dataset['test']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7f1475b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-14T20:23:15.909900Z",
     "iopub.status.busy": "2021-05-14T20:23:15.909254Z",
     "iopub.status.idle": "2021-05-14T20:23:15.911955Z",
     "shell.execute_reply": "2021-05-14T20:23:15.912576Z"
    },
    "papermill": {
     "duration": 0.075627,
     "end_time": "2021-05-14T20:23:15.912716",
     "exception": false,
     "start_time": "2021-05-14T20:23:15.837089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_set = dataset_dic_test[testing_domain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e0f1c60",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-14T20:23:16.053390Z",
     "iopub.status.busy": "2021-05-14T20:23:16.052745Z",
     "iopub.status.idle": "2021-05-14T20:23:16.056573Z",
     "shell.execute_reply": "2021-05-14T20:23:16.056014Z"
    },
    "executionInfo": {
     "elapsed": 69558,
     "status": "ok",
     "timestamp": 1615649224592,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "Tu7xUHpGkzCm",
    "outputId": "cb6d1569-85ba-4062-8d2e-ceac29ebfce6",
    "papermill": {
     "duration": 0.075732,
     "end_time": "2021-05-14T20:23:16.056700",
     "exception": false,
     "start_time": "2021-05-14T20:23:15.980968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(test_set[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba39cd1",
   "metadata": {
    "id": "3jNAtuv-hbzv",
    "papermill": {
     "duration": 0.068281,
     "end_time": "2021-05-14T20:23:16.193462",
     "exception": false,
     "start_time": "2021-05-14T20:23:16.125181",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load the pretrained LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4284184",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-14T20:23:16.335407Z",
     "iopub.status.busy": "2021-05-14T20:23:16.334754Z",
     "iopub.status.idle": "2021-05-14T20:23:27.309541Z",
     "shell.execute_reply": "2021-05-14T20:23:27.310551Z"
    },
    "executionInfo": {
     "elapsed": 84199,
     "status": "ok",
     "timestamp": 1615649239241,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "En2BmfjVhbzy",
    "papermill": {
     "duration": 11.04927,
     "end_time": "2021-05-14T20:23:27.310835",
     "exception": false,
     "start_time": "2021-05-14T20:23:16.261565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load pretrained language model\n",
    "nli_model = transformers.AutoModelForSequenceClassification.from_pretrained(nli_model_path)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"textattack/bert-base-uncased-MNLI\", cache_dir='../bert_base_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f181619c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-14T20:23:27.514232Z",
     "iopub.status.busy": "2021-05-14T20:23:27.513582Z",
     "iopub.status.idle": "2021-05-14T20:23:38.757268Z",
     "shell.execute_reply": "2021-05-14T20:23:38.758309Z"
    },
    "papermill": {
     "duration": 11.327761,
     "end_time": "2021-05-14T20:23:38.758592",
     "exception": false,
     "start_time": "2021-05-14T20:23:27.430831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NLISentimentClassificationHead(\n",
       "  (nli_model): BertForSequenceClassification(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = utils.NLISentimentClassificationHead(\n",
    "                    nli_model = nli_model,\n",
    "                    num_prompts = len(sentiment_prompts),\n",
    "                    pos_prompt_indexes = pos_prompt_indexes,\n",
    "                    neg_prompt_indexes = neg_prompt_indexes\n",
    "                    )\n",
    "classifier.to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "892867da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-14T20:23:38.940588Z",
     "iopub.status.busy": "2021-05-14T20:23:38.939929Z",
     "iopub.status.idle": "2021-05-14T20:23:45.776786Z",
     "shell.execute_reply": "2021-05-14T20:23:45.775745Z"
    },
    "papermill": {
     "duration": 6.917202,
     "end_time": "2021-05-14T20:23:45.777055",
     "exception": false,
     "start_time": "2021-05-14T20:23:38.859853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading epoch_18.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Locate the weight file.\n",
    "trained_model_directory = os.path.join('..', 'trained_models', experiment_id)\n",
    "\n",
    "saved_weights_name = ''\n",
    "\n",
    "for fname in os.listdir(trained_model_directory):\n",
    "    if fname.startswith('epoch'):\n",
    "        saved_weights_name = fname\n",
    "        break\n",
    "\n",
    "print(\"Loading\", saved_weights_name)\n",
    "\n",
    "classifier.load_state_dict(torch.load(\n",
    "    os.path.join(trained_model_directory, saved_weights_name),\n",
    "    map_location=torch_device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67d99d5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-14T20:23:45.962398Z",
     "iopub.status.busy": "2021-05-14T20:23:45.961745Z",
     "iopub.status.idle": "2021-05-14T20:23:45.965312Z",
     "shell.execute_reply": "2021-05-14T20:23:45.964648Z"
    },
    "executionInfo": {
     "elapsed": 379,
     "status": "ok",
     "timestamp": 1615649260278,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "0S80DoYrqApi",
    "papermill": {
     "duration": 0.084759,
     "end_time": "2021-05-14T20:23:45.965446",
     "exception": false,
     "start_time": "2021-05-14T20:23:45.880687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(predictions, labels):\n",
    "    preds = predictions.argmax(-1)\n",
    "\n",
    "    precision, recall, f1, _ = sklearn.metrics.precision_recall_fscore_support(\n",
    "        y_true=labels, y_pred=preds, labels=[0,1,2], average='macro')\n",
    "\n",
    "    acc = sklearn.metrics.accuracy_score(labels, preds)\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebb2a5b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-14T20:23:46.112314Z",
     "iopub.status.busy": "2021-05-14T20:23:46.111657Z",
     "iopub.status.idle": "2021-05-14T20:23:46.115365Z",
     "shell.execute_reply": "2021-05-14T20:23:46.114830Z"
    },
    "executionInfo": {
     "elapsed": 526,
     "status": "ok",
     "timestamp": 1615652664827,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "9NXoBTs5h2eO",
    "papermill": {
     "duration": 0.079493,
     "end_time": "2021-05-14T20:23:46.115493",
     "exception": false,
     "start_time": "2021-05-14T20:23:46.036000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_set, batch_size=testing_batch_size, pin_memory=use_pin_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4acb2d7",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e948fca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-14T20:23:46.307554Z",
     "iopub.status.busy": "2021-05-14T20:23:46.270235Z",
     "iopub.status.idle": "2021-05-14T20:23:47.200402Z",
     "shell.execute_reply": "2021-05-14T20:23:47.198258Z"
    },
    "papermill": {
     "duration": 1.014773,
     "end_time": "2021-05-14T20:23:47.200939",
     "exception": true,
     "start_time": "2021-05-14T20:23:46.186166",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f047fbbed524ffeb7069254e29b2a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cannot perform reduction function argmax on a tensor with no elements because the operation does not have an identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-8e137de3867d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Compute metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mtest_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-d6668935323b>\u001b[0m in \u001b[0;36mcompute_metrics\u001b[0;34m(predictions, labels)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     precision, recall, f1, _ = sklearn.metrics.precision_recall_fscore_support(\n\u001b[1;32m      5\u001b[0m         y_true=labels, y_pred=preds, labels=[0,1,2], average='macro')\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cannot perform reduction function argmax on a tensor with no elements because the operation does not have an identity"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the best found head weights\n",
    "with torch.no_grad():\n",
    "\n",
    "    classifier.eval()\n",
    "\n",
    "    predictions_test = torch.Tensor().to(torch_device)\n",
    "\n",
    "    labels_test = torch.Tensor().to(torch_device)\n",
    "\n",
    "    for batch_test in tqdm.notebook.tqdm(test_dataloader):\n",
    "\n",
    "        reviews_repeated = []\n",
    "        prompts_populated = []\n",
    "\n",
    "        for i in range(len(batch_test[\"text\"])):\n",
    "            \n",
    "            for prompt in sentiment_prompts:\n",
    "                reviews_repeated.append(batch_test[\"text\"][i])\n",
    "                prompts_populated.append(prompt.format(aspect=batch_test[\"aspect\"][i]))\n",
    "\n",
    "        batch_encoded = tokenizer(\n",
    "            reviews_repeated, prompts_populated,\n",
    "            padding='max_length', truncation='only_first', max_length=256,\n",
    "            return_tensors='pt')\n",
    "        \n",
    "        batch_encoded.to(torch_device)\n",
    "\n",
    "        nli_output = nli_model(**batch_encoded)[\"logits\"]\n",
    "\n",
    "        labels = batch_test[\"sentiment\"]\n",
    "        labels = labels.to(torch_device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = classifier(batch_encoded)\n",
    "        \n",
    "        predictions_test = torch.cat([predictions_test, outputs])\n",
    "        labels_test = torch.cat([labels_test, labels])\n",
    "\n",
    "    # Compute metrics\n",
    "    test_metrics = compute_metrics(predictions_test.cpu(), labels_test.cpu())\n",
    "    \n",
    "    print(test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c8f49f",
   "metadata": {
    "id": "HjpA_0m1hb08",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Results visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c02ff82",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "executionInfo": {
     "elapsed": 57879,
     "status": "ok",
     "timestamp": 1615652727259,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "w9G9AUeQhb09",
    "outputId": "c3233dd7-5d3e-4ac8-c9c8-dcae0b306f85",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate metrics and confusion matrix based upon predictions and true labels\n",
    "cm = sklearn.metrics.confusion_matrix(labels_test.cpu().detach().numpy(), predictions_test.cpu().detach().numpy().argmax(-1), labels=[0,1,2])\n",
    "\n",
    "df_cm = pd.DataFrame(\n",
    "    cm,\n",
    "    index=[i for i in [\"positive\", \"negative\", \"neutral\"]],\n",
    "    columns=[i for i in [\"positive\", \"negative\", \"neutral\"]])\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "ax = sn.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "\n",
    "ax.set(xlabel='Predicted Label', ylabel='True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028e61f5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [],
   "name": "prompt_lr_atsc_bert_amazon_electronics.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('zero_shot': conda)",
   "name": "python388jvsc74a57bd0a74be8730e03c7381f29dbaf8be9c0282b9666254c68a0570d010444c486b615"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 52.653929,
   "end_time": "2021-05-14T20:23:49.216417",
   "environment_variables": {},
   "exception": true,
   "input_path": "nli_subtask4_template.ipynb",
   "output_path": "results_nli_few_shot_in_domain/nli_few_shot_in_domain_laptops_16_MNLI-base_the_aspect_is_696.ipynb",
   "parameters": {
    "experiment_id": "nli_few_shot_in_domain_laptops_16_MNLI-base_the_aspect_is_696",
    "neg_prompt_indexes": [
     1
    ],
    "nli_model_path": "textattack/bert-base-uncased-MNLI",
    "pos_prompt_indexes": [
     0
    ],
    "random_seed": 696,
    "sample_size": 16,
    "sentiment_prompts": [
     "The {aspect} is good.",
     "The {aspect} is bad."
    ],
    "testing_batch_size": 8,
    "testing_domain": "laptops"
   },
   "start_time": "2021-05-14T20:22:56.562488",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1f047fbbed524ffeb7069254e29b2a1c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b81a427e07ac4e13afaa3ebfd2c0d2fc",
        "IPY_MODEL_fde84e7c6b574469878b644b8dfc548d"
       ],
       "layout": "IPY_MODEL_3707aecbc724412dbba5f5bb4e3f4fe5"
      }
     },
     "3707aecbc724412dbba5f5bb4e3f4fe5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "376b5e1c09874be38cf547bb39af8d49": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "80e5724259b54abd8c55c6c618b9ccf7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "b81a427e07ac4e13afaa3ebfd2c0d2fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_80e5724259b54abd8c55c6c618b9ccf7",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f0d93c73472f47258317029fd8640ce7",
       "value": 0.0
      }
     },
     "c973fe7070224499861466f0fe4d146d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f0d93c73472f47258317029fd8640ce7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "fde84e7c6b574469878b644b8dfc548d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_376b5e1c09874be38cf547bb39af8d49",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_c973fe7070224499861466f0fe4d146d",
       "value": "0it [00:00, ?it/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
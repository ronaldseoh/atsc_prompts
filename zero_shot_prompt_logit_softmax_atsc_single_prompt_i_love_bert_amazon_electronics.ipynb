{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xf3lVTZYhbzA"
   },
   "source": [
    "# Initial Setups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ORFXeezn5Og"
   },
   "source": [
    "## (Google Colab use only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40357,
     "status": "ok",
     "timestamp": 1615623846888,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "YFAQ6IgXn8FK",
    "outputId": "33b5b742-821d-47c0-de7e-20d05424bf7d"
   },
   "outputs": [],
   "source": [
    "# Use Google Colab\n",
    "use_colab = True\n",
    "\n",
    "# Is this notebook running on Colab?\n",
    "# If so, then google.colab package (github.com/googlecolab/colabtools)\n",
    "# should be available in this environment\n",
    "\n",
    "# Previous version used importlib, but we could do the same thing with\n",
    "# just attempting to import google.colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    colab_available = True\n",
    "except:\n",
    "    colab_available = False\n",
    "\n",
    "if use_colab and colab_available:\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # cd to the appropriate working directory under my Google Drive\n",
    "    %cd '/content/drive/My Drive/cs696ds_lexalytics/Prompting Experiments'\n",
    "    \n",
    "    # Install packages specified in requirements\n",
    "    !pip install -r requirements.txt\n",
    "    \n",
    "    # List the directory contents\n",
    "    !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgzsHF7Zhbzo"
   },
   "source": [
    "## Experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 40350,
     "status": "ok",
     "timestamp": 1615623846892,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "DUpGBmOJhbzs"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# We will use the following string ID to identify this particular (training) experiments\n",
    "# in directory paths and other settings\n",
    "experiment_id = 'prompt_lr_atsc_single_prompt_logit_softmax_i_love_bert_amazon_electronics'\n",
    "\n",
    "# Random seed\n",
    "random_seed = 696\n",
    "\n",
    "# path to pretrained MLM model folder or the string \"bert-base-uncased\"\n",
    "mlm_model_path = os.path.join(\n",
    "    'progress', 'lm_further_pretraining_bert_amazon_electronics_bseoh_2021-03-06--18_59_53',\n",
    "    'results', 'checkpoint-1180388')\n",
    "\n",
    "# Prompts to be added to the end of each review text\n",
    "# Note: pseudo-labels for each prompt should be given in the order of (positive), (negative), (neutral)\n",
    "sentiment_prompts = [\n",
    "    {\"prompt\": \"I [MASK] the {aspect}.\", \"labels\": [\"love\", \"hate\", \"dislike\"]}\n",
    "]\n",
    "\n",
    "# Test settings\n",
    "lr_testing_batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYZesqTioMvF"
   },
   "source": [
    "## Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49168,
     "status": "ok",
     "timestamp": 1615623855723,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "MlK_-DrWhbzb",
    "outputId": "c4846c32-16cf-495a-c053-7589a2b619ce"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "import datasets\n",
    "import sklearn.metrics\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import tqdm\n",
    "\n",
    "import utils\n",
    "\n",
    "# Random seed settings\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "# Print version information\n",
    "print(\"Python version: \" + sys.version)\n",
    "print(\"NumPy version: \" + np.__version__)\n",
    "print(\"PyTorch version: \" + torch.__version__)\n",
    "print(\"Transformers version: \" + transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UWuR30eUoTWP"
   },
   "source": [
    "## PyTorch GPU settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49160,
     "status": "ok",
     "timestamp": 1615623855725,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "PfNlm-ykoSlM",
    "outputId": "ae25b1b3-2ee1-41ef-a72c-328806832240"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():    \n",
    "    torch_device = torch.device('cuda')\n",
    "\n",
    "    # Set this to True to make your output immediately reproducible\n",
    "    # Note: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    \n",
    "    # Disable 'benchmark' mode: Set this False if you want to measure running times more fairly\n",
    "    # Note: https://discuss.pytorch.org/t/what-does-torch-backends-cudnn-benchmark-do/5936\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    # Faster Host to GPU copies with page-locked memory\n",
    "    use_pin_memory = True\n",
    "    \n",
    "    # Number of compute devices to be used for training\n",
    "    training_device_count = torch.cuda.device_count()\n",
    "\n",
    "    # CUDA libraries version information\n",
    "    print(\"CUDA Version: \" + str(torch.version.cuda))\n",
    "    print(\"cuDNN Version: \" + str(torch.backends.cudnn.version()))\n",
    "    print(\"CUDA Device Name: \" + str(torch.cuda.get_device_name()))\n",
    "    print(\"CUDA Capabilities: \"+ str(torch.cuda.get_device_capability()))\n",
    "    print(\"Number of CUDA devices: \"+ str(training_device_count))\n",
    "    \n",
    "else:\n",
    "    torch_device = torch.device('cpu')\n",
    "    use_pin_memory = False\n",
    "    \n",
    "    # Number of compute devices to be used for training\n",
    "    training_device_count = 1\n",
    "\n",
    "print()\n",
    "print(\"PyTorch device selected:\", torch_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayX5VRLfocFk"
   },
   "source": [
    "# Prepare Datasets for Prompt-based Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9LAAJP-hbz7"
   },
   "source": [
    "## Load the SemEval dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53247,
     "status": "ok",
     "timestamp": 1615623859823,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "gpL2uHPUhbz9",
    "outputId": "8b51ee70-fc4f-4b05-857c-78fb23ed0c75"
   },
   "outputs": [],
   "source": [
    "# Load semeval for both domains\n",
    "in_domain_semeval_dataset = datasets.load_dataset(\n",
    "    os.path.abspath('dataset_scripts/semeval2014_task4/semeval2014_task4.py'),\n",
    "    data_files={\n",
    "        'test': 'dataset_files/semeval_2014/Laptops_Test_Gold.xml',\n",
    "        'train': 'dataset_files/semeval_2014/Laptop_Train_v2.xml',\n",
    "    },\n",
    "    cache_dir='dataset_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 53242,
     "status": "ok",
     "timestamp": 1615623859824,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "Gi5m8AbPj1iJ"
   },
   "outputs": [],
   "source": [
    "in_domain_test = in_domain_semeval_dataset['test'] # Never use in-domain training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TOMmAtIvoZ_"
   },
   "source": [
    "# Zero-shot ATSC with Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3jNAtuv-hbzv"
   },
   "source": [
    "## Load the pretrained LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 66643,
     "status": "ok",
     "timestamp": 1615623873231,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "En2BmfjVhbzy"
   },
   "outputs": [],
   "source": [
    "# Load pretrained language model\n",
    "mlm = transformers.AutoModelForMaskedLM.from_pretrained(mlm_model_path)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained('bert-base-uncased', cache_dir='bert_base_cache')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEIbN5Xthb0o"
   },
   "source": [
    "## Define a new model with non-trainable softmax head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 77684,
     "status": "ok",
     "timestamp": 1615623884280,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "wN3q4Rsopxby",
    "outputId": "7a22e0b8-30fe-4a9d-a8af-f89f3f1e7322"
   },
   "outputs": [],
   "source": [
    "# Encode the pseudo-label words for each sentiment class\n",
    "sentiment_word_ids = []\n",
    "\n",
    "for w in sentiment_prompts[0]['labels']:\n",
    "    sentiment_word_ids.append(tokenizer.convert_tokens_to_ids(w))\n",
    "\n",
    "print(sentiment_word_ids)\n",
    "\n",
    "classifier_model = utils.SinglePromptLogitSentimentClassificationHead(\n",
    "    mlm=mlm,\n",
    "    num_class=3, pseudo_label_words=sentiment_word_ids, mask_token_id=tokenizer.mask_token_id)\n",
    "\n",
    "# Freeze the MLM main layer\n",
    "for param in classifier_model.mlm.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "classifier_model = classifier_model.to(device=torch_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1l1H_XIPhb0y"
   },
   "source": [
    "## Evaluation with in-domain test set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 77688,
     "status": "ok",
     "timestamp": 1615623884289,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "0S80DoYrqApi"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(predictions, labels):\n",
    "    preds = predictions.argmax(-1)\n",
    "\n",
    "    precision, recall, f1, _ = sklearn.metrics.precision_recall_fscore_support(\n",
    "        y_true=labels, y_pred=preds, labels=[0,1,2], average='macro')\n",
    "\n",
    "    acc = sklearn.metrics.accuracy_score(labels, preds)\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 77688,
     "status": "ok",
     "timestamp": 1615623884292,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "9NXoBTs5h2eO"
   },
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    in_domain_test, batch_size=lr_testing_batch_size,\n",
    "    pin_memory=use_pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138,
     "referenced_widgets": [
      "9f92bba9b0f44fffa44ce9a2249c6ae3",
      "6114d094a0844e69bfd823310d54b738",
      "cba60727f6f44f1aaad93a48af9fa875",
      "414e9eb3830b43c1907e250559370f70",
      "984e9aff13ea4141b9f5194c45f07ae7",
      "b2de8e2070244df3bddc6e68d2c73ab2",
      "c3148378f0c24208984b26d75621cdff",
      "b161f82b936c42469ddd3186ba28124d"
     ]
    },
    "executionInfo": {
     "elapsed": 90062,
     "status": "ok",
     "timestamp": 1615623896679,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "LLcc_wZjhb0y",
    "outputId": "4f154371-55ea-45f5-d044-706f5b80f1ff"
   },
   "outputs": [],
   "source": [
    "classifier_model.eval()\n",
    "\n",
    "predictions_test = torch.Tensor([])\n",
    "labels_test = torch.Tensor([])\n",
    "\n",
    "for batch_val in tqdm.notebook.tqdm(test_dataloader):\n",
    "\n",
    "    reviews_repeated = []\n",
    "    prompts_populated = []\n",
    "\n",
    "    for prompt in sentiment_prompts:\n",
    "        reviews_repeated = reviews_repeated + batch_val[\"text\"]\n",
    "\n",
    "        for aspect in batch_val[\"aspect\"]:\n",
    "            prompts_populated.append(prompt['prompt'].format(aspect=aspect))\n",
    "\n",
    "    batch_encoded = tokenizer(\n",
    "        reviews_repeated, prompts_populated,\n",
    "        padding='max_length', truncation='only_first', max_length=256,\n",
    "        return_tensors='pt')\n",
    "    \n",
    "    batch_encoded.to(torch_device)\n",
    "\n",
    "    labels = batch_val[\"sentiment\"]\n",
    "\n",
    "    outputs = classifier_model(batch_encoded)\n",
    "\n",
    "    outputs = outputs.to('cpu')\n",
    "\n",
    "    predictions_test = torch.cat([predictions_test, outputs])\n",
    "    labels_test = torch.cat([labels_test, labels])\n",
    "\n",
    "# Compute metrics\n",
    "test_metrics = compute_metrics(predictions_test, labels_test)\n",
    "\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjpA_0m1hb08"
   },
   "source": [
    "## Results visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "executionInfo": {
     "elapsed": 90356,
     "status": "ok",
     "timestamp": 1615623896983,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "w9G9AUeQhb09",
    "outputId": "a875c15d-7ccc-49d4-acf9-e645e389fb93"
   },
   "outputs": [],
   "source": [
    "# Calculate metrics and confusion matrix based upon predictions and true labels\n",
    "cm = sklearn.metrics.confusion_matrix(labels_test.detach().numpy(), predictions_test.detach().numpy().argmax(-1))\n",
    "\n",
    "df_cm = pd.DataFrame(\n",
    "    cm,\n",
    "    index=[i for i in [\"positive\", \"negative\", \"neutral\"]],\n",
    "    columns=[i for i in [\"positive\", \"negative\", \"neutral\"]])\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "ax = sn.heatmap(df_cm, annot=True)\n",
    "\n",
    "ax.set(xlabel='Predicted Label', ylabel='True Label')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "prompt_lr_atsc_single_prompt_logit_softmax_i_love_bert_amazon_electronics.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "414e9eb3830b43c1907e250559370f70": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b161f82b936c42469ddd3186ba28124d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c3148378f0c24208984b26d75621cdff",
      "value": " 20/20 [00:12&lt;00:00,  1.59it/s]"
     }
    },
    "6114d094a0844e69bfd823310d54b738": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "984e9aff13ea4141b9f5194c45f07ae7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9f92bba9b0f44fffa44ce9a2249c6ae3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cba60727f6f44f1aaad93a48af9fa875",
       "IPY_MODEL_414e9eb3830b43c1907e250559370f70"
      ],
      "layout": "IPY_MODEL_6114d094a0844e69bfd823310d54b738"
     }
    },
    "b161f82b936c42469ddd3186ba28124d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2de8e2070244df3bddc6e68d2c73ab2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3148378f0c24208984b26d75621cdff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cba60727f6f44f1aaad93a48af9fa875": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2de8e2070244df3bddc6e68d2c73ab2",
      "max": 20,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_984e9aff13ea4141b9f5194c45f07ae7",
      "value": 20
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
